{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import wandb\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.login(key=\"b4dc866a06ba17317c20de0d13c1a64cc23096dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TO USE GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_csv = \"/kaggle/input/dakshina-dataset-hindi/DakshinaDataSet_Hindi/hindi_Train_dataset.csv\"\n",
    "test_csv = \"/kaggle/input/dakshina-dataset-hindi/DakshinaDataSet_Hindi/hindi_Test_dataset.csv\"\n",
    "val_csv = \"/kaggle/input/dakshina-dataset-hindi/DakshinaDataSet_Hindi/hindi_Validation_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "train_data = pd.read_csv(train_csv, header=None)\n",
    "train_input = train_data[0].to_numpy()\n",
    "train_output = train_data[1].to_numpy()\n",
    "val_data = pd.read_csv(val_csv, header=None)\n",
    "val_input = val_data[0].to_numpy()\n",
    "val_output = val_data[1].to_numpy()\n",
    "test_data = pd.read_csv(test_csv, header=None)\n",
    "test_input = test_data[0].to_numpy()\n",
    "test_output = test_data[1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pre_processing(train_input, train_output):\n",
    "    data = {\n",
    "        \"all_characters\": [],\n",
    "        \"char_num_map\": {},\n",
    "        \"num_char_map\": {},\n",
    "        \"source_charToNum\": torch.zeros(len(train_input), 30, dtype=torch.int, device=device),\n",
    "        \"source_data\": train_input,\n",
    "        \"all_characters_2\": [],\n",
    "        \"char_num_map_2\": {},\n",
    "        \"num_char_map_2\": {},\n",
    "        \"val_charToNum\": torch.zeros(len(train_output), 23, dtype=torch.int, device=device),\n",
    "        \"target_data\": train_output,\n",
    "        \"source_len\": 0,\n",
    "        \"target_len\": 0\n",
    "    }\n",
    "    \n",
    "    for i in range(len(train_input)):\n",
    "        train_input[i] = \"{\" + train_input[i] + \"}\" * (29 - len(train_input[i]))\n",
    "        charToNum = []\n",
    "        for char in train_input[i]:\n",
    "            if char not in data[\"all_characters\"]:\n",
    "                data[\"all_characters\"].append(char)\n",
    "                index = len(data[\"all_characters\"]) - 1\n",
    "                data[\"char_num_map\"][char] = index\n",
    "                data[\"num_char_map\"][index] = char\n",
    "            else:\n",
    "                index = data[\"char_num_map\"][char]\n",
    "            charToNum.append(index)\n",
    "        data[\"source_charToNum\"][i] = torch.tensor(charToNum, device=device)\n",
    "\n",
    "        train_output[i] = \"{\" + train_output[i] + \"}\" * (22 - len(train_output[i]))\n",
    "        charToNum1 = []\n",
    "        for char in train_output[i]:\n",
    "            if char not in data[\"all_characters_2\"]:\n",
    "                data[\"all_characters_2\"].append(char)\n",
    "                index = len(data[\"all_characters_2\"]) - 1\n",
    "                data[\"char_num_map_2\"][char] = index\n",
    "                data[\"num_char_map_2\"][index] = char\n",
    "            else:\n",
    "                index = data[\"char_num_map_2\"][char]\n",
    "            charToNum1.append(index)\n",
    "        data[\"val_charToNum\"][i] = torch.tensor(charToNum1, device=device)\n",
    "    \n",
    "    data[\"source_len\"] = len(data[\"all_characters\"])\n",
    "    data[\"target_len\"] = len(data[\"all_characters_2\"])\n",
    "    return data\n",
    "\n",
    "data = pre_processing(copy.copy(train_input), copy.copy(train_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pre_processing_validation(val_input, val_output):\n",
    "    data2 = {\n",
    "        \"source_charToNum\": torch.zeros(len(val_input), 30, dtype=torch.int, device=device),\n",
    "        \"val_charToNum\": torch.zeros(len(val_output), 23, dtype=torch.int, device=device)\n",
    "    }\n",
    "    m1 = data[\"char_num_map\"]\n",
    "    m2 = data[\"char_num_map_2\"]\n",
    "    \n",
    "    for i in range(len(val_input)):\n",
    "        val_input[i] = \"{\" + val_input[i] + \"}\" * (29 - len(val_input[i]))\n",
    "        charToNum = [m1[char] for char in val_input[i]]\n",
    "        data2[\"source_charToNum\"][i] = torch.tensor(charToNum, device=device)\n",
    "        \n",
    "        val_output[i] = \"{\" + val_output[i] + \"}\" * (22 - len(val_output[i]))\n",
    "        charToNum1 = [m2[char] for char in val_output[i]]\n",
    "        data2[\"val_charToNum\"][i] = torch.tensor(charToNum1, device=device)\n",
    "    \n",
    "    return data2\n",
    "\n",
    "data2 = pre_processing_validation(copy.copy(val_input), copy.copy(val_output))\n",
    "data_test = pre_processing_validation(copy.copy(test_input), copy.copy(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class for PyTorch\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # Store input (x) and target (y) data\n",
    "        self.source = x\n",
    "        self.target = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return number of samples\n",
    "        return len(self.source)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return a single data sample pair\n",
    "        return self.source[idx], self.target[idx]\n",
    "\n",
    "# DataLoader wrapper function for train/validation datasets\n",
    "def dataLoaderFun(dataName, batch_size):\n",
    "    if dataName == 'train':\n",
    "        dataset = MyDataset(data[\"source_charToNum\"], data['val_charToNum'])\n",
    "    else:\n",
    "        dataset = MyDataset(data2[\"source_charToNum\"], data2['val_charToNum'])\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Encoder class using RNN/GRU/LSTM\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, inputDim, embSize, encoderLayers, hiddenLayerNuerons, cellType, bidirection):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(inputDim, embSize)\n",
    "        self.encoderLayers = encoderLayers\n",
    "        self.hiddenLayerNuerons = hiddenLayerNuerons\n",
    "        self.bidirection = bidirection\n",
    "        self.num_directions = 2 if bidirection == \"Yes\" else 1\n",
    "\n",
    "        # Choose RNN cell type\n",
    "        if cellType == 'GRU':\n",
    "            self.rnn = nn.GRU(embSize, hiddenLayerNuerons, num_layers=encoderLayers,\n",
    "                              bidirectional=(bidirection == \"Yes\"), batch_first=True)\n",
    "        elif cellType == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embSize, hiddenLayerNuerons, num_layers=encoderLayers,\n",
    "                               bidirectional=(bidirection == \"Yes\"), batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embSize, hiddenLayerNuerons, num_layers=encoderLayers,\n",
    "                              bidirectional=(bidirection == \"Yes\"), batch_first=True)\n",
    "    \n",
    "    def initHidden(self, batch_size=1):\n",
    "        h0 = torch.zeros(self.encoderLayers * self.num_directions,\n",
    "                         batch_size,\n",
    "                         self.hiddenLayerNuerons,\n",
    "                         device=device)\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            c0 = torch.zeros_like(h0)\n",
    "            return (h0, c0)\n",
    "        else:\n",
    "            return h0\n",
    "        \n",
    "    def forward(self, currentInput, prevState):\n",
    "        # Embed input and pass through RNN\n",
    "        embdInput = self.embedding(currentInput)\n",
    "        return self.rnn(embdInput, prevState)\n",
    "\n",
    "    def getInitialState(self, batch_size):\n",
    "        # Create zero initial hidden state\n",
    "        return torch.zeros(self.encoderLayers * self.num_directions, batch_size, self.hiddenLayerNuerons, device=device)\n",
    "\n",
    "# Decoder class using RNN/GRU/LSTM\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, outputDim, embSize, hiddenLayerNuerons, decoderLayers, cellType, dropout_p):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(outputDim, embSize)\n",
    "        self.decoderLayers = decoderLayers\n",
    "\n",
    "        # Choose RNN cell type\n",
    "        if cellType == 'GRU':\n",
    "            self.rnn = nn.GRU(embSize, hiddenLayerNuerons, num_layers=decoderLayers, batch_first=True)\n",
    "        elif cellType == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embSize, hiddenLayerNuerons, num_layers=decoderLayers, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(embSize, hiddenLayerNuerons, num_layers=decoderLayers, batch_first=True)\n",
    "\n",
    "        # Output layer and softmax\n",
    "        self.fc = nn.Linear(hiddenLayerNuerons, outputDim)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, currentInput, prevState):\n",
    "        # Forward pass through embedding, RNN, and output layer\n",
    "        embdInput = self.embedding(currentInput)\n",
    "        output, prevState = self.rnn(embdInput, prevState)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(self.fc(output))\n",
    "        return output, prevState\n",
    "\n",
    "# Adjust encoder hidden state for decoder\n",
    "def init_decoder_state(encoder_state, encoderLayers, decoderLayers, cellType):\n",
    "    if cellType == 'LSTM':\n",
    "        h, c = encoder_state\n",
    "        # Adjust hidden and cell state sizes\n",
    "        if encoderLayers >= decoderLayers:\n",
    "            return (h[-decoderLayers:], c[-decoderLayers:])\n",
    "        else:\n",
    "            # Duplicate last layer if decoder has more layers\n",
    "            h_dec = torch.cat([h] + [h[-1:]]*(decoderLayers - encoderLayers), dim=0)\n",
    "            c_dec = torch.cat([c] + [c[-1:]]*(decoderLayers - encoderLayers), dim=0)\n",
    "            return (h_dec, c_dec)\n",
    "    else:\n",
    "        h = encoder_state\n",
    "        if encoderLayers >= decoderLayers:\n",
    "            return h[-decoderLayers:]\n",
    "        else:\n",
    "            return torch.cat([h] + [h[-1:]]*(decoderLayers - encoderLayers), dim=0)\n",
    "\n",
    "# Training loop\n",
    "def train(embSize, encoderLayers, decoderLayers, hiddenLayerNuerons, cellType, bidirection, dropout, epochs, batchsize, learningRate, optimizer, tf_ratio):\n",
    "    dataLoader = dataLoaderFun(\"train\", batchsize)\n",
    "    lossFunction = nn.NLLLoss()\n",
    "    \n",
    "    # Initialize encoder and decoder\n",
    "    encoder = Encoder(data[\"source_len\"], embSize, encoderLayers, hiddenLayerNuerons, cellType, bidirection).to(device)\n",
    "    decoder = Decoder(data[\"target_len\"], embSize, hiddenLayerNuerons, decoderLayers, cellType, dropout).to(device)\n",
    "\n",
    "    # Set optimizer\n",
    "    if optimizer == 'Adam':\n",
    "        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n",
    "        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n",
    "    else:\n",
    "        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n",
    "        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_accuracy = 0\n",
    "        train_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n",
    "            current_batch_size = sourceBatch.size(0)\n",
    "            encoderInitialState = encoder.getInitialState(current_batch_size)\n",
    "\n",
    "            # Handle bidirection by averaging forward and backward pass input\n",
    "            if bidirection == \"Yes\":\n",
    "                reversed_batch = torch.flip(sourceBatch, dims=[1])\n",
    "                sourceBatch = (sourceBatch + reversed_batch) // 2\n",
    "\n",
    "            if cellType == 'LSTM':\n",
    "                encoderInitialState = (encoderInitialState, torch.zeros_like(encoderInitialState))\n",
    "\n",
    "            # Forward pass through encoder\n",
    "            encoder_output, encoderCurrentState = encoder(sourceBatch, encoderInitialState)\n",
    "\n",
    "            # Reduce bidirectional state\n",
    "            if bidirection == \"Yes\":\n",
    "                if cellType == 'LSTM':\n",
    "                    encoderCurrentState = (\n",
    "                        encoderCurrentState[0].view(encoderLayers, 2, current_batch_size, -1).sum(1),\n",
    "                        encoderCurrentState[1].view(encoderLayers, 2, current_batch_size, -1).sum(1)\n",
    "                    )\n",
    "                else:\n",
    "                    encoderCurrentState = encoderCurrentState.view(encoderLayers, 2, current_batch_size, -1).sum(1)\n",
    "\n",
    "            decoderCurrState = init_decoder_state(encoderCurrentState, encoderLayers, decoderLayers, cellType)\n",
    "\n",
    "            loss = 0\n",
    "            sequenceLen = targetBatch.shape[1]\n",
    "            Output = []\n",
    "            randNumber = random.random()\n",
    "\n",
    "            # Decoder loop\n",
    "            for i in range(sequenceLen):\n",
    "                if i == 0:\n",
    "                    decoderInput = targetBatch[:, i].reshape(current_batch_size, 1)\n",
    "                else:\n",
    "                    # Teacher forcing\n",
    "                    if randNumber < tf_ratio:\n",
    "                        decoderInput = targetBatch[:, i].reshape(current_batch_size, 1)\n",
    "                    else:\n",
    "                        decoderInput = decoderInput.reshape(current_batch_size, 1)\n",
    "\n",
    "                decoderOutput, decoderCurrState = decoder(decoderInput, decoderCurrState)\n",
    "                _, topIndeces = decoderOutput.topk(1)\n",
    "                decoderOutput = decoderOutput[:, -1, :]\n",
    "                targetChars = targetBatch[:, i].type(dtype=torch.long)\n",
    "                loss += lossFunction(decoderOutput, targetChars)\n",
    "                decoderInput = topIndeces.squeeze().detach()\n",
    "                Output.append(decoderInput)\n",
    "\n",
    "            # Stack outputs and compute accuracy/loss\n",
    "            tensor_2d = torch.stack(Output)\n",
    "            Output = tensor_2d.t()\n",
    "            train_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n",
    "            train_loss += (loss.item() / sequenceLen)\n",
    "            total_samples += targetBatch.size(0)\n",
    "\n",
    "            encoderOptimizer.zero_grad()\n",
    "            decoderOptimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            encoderOptimizer.step()\n",
    "            decoderOptimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_acc, val_loss = validationAccuracy(encoder, decoder, batchsize, tf_ratio, cellType, bidirection)\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss / len(dataLoader),\n",
    "            \"train_accuracy\": train_accuracy / total_samples,\n",
    "            \"validation_loss\": val_loss / len(dataLoaderFun(\"validation\", batchsize)),\n",
    "            \"validation_accuracy\": val_acc / sum(len(b) for b, _ in dataLoaderFun(\"validation\", batchsize))\n",
    "        })\n",
    "\n",
    "# Validation function\n",
    "def validationAccuracy(encoder, decoder, batchsize, tf_ratio, cellType, bidirection):\n",
    "    dataLoader = dataLoaderFun(\"validation\", batchsize)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    validation_accuracy = 0\n",
    "    validation_loss = 0\n",
    "    total_samples = 0\n",
    "    lossFunction = nn.NLLLoss()\n",
    "\n",
    "    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n",
    "        current_batch_size = sourceBatch.size(0)\n",
    "        encoderInitialState = encoder.getInitialState(current_batch_size)\n",
    "\n",
    "        if cellType == 'LSTM':\n",
    "            encoderInitialState = (encoderInitialState, torch.zeros_like(encoderInitialState))\n",
    "\n",
    "        if bidirection == \"Yes\":\n",
    "            reversed_batch = torch.flip(sourceBatch, dims=[1])\n",
    "            sourceBatch = (sourceBatch + reversed_batch) // 2\n",
    "\n",
    "        encoder_output, encoderCurrentState = encoder(sourceBatch, encoderInitialState)\n",
    "\n",
    "        if bidirection == \"Yes\":\n",
    "            if cellType == 'LSTM':\n",
    "                encoderCurrentState = (\n",
    "                    encoderCurrentState[0].view(encoder.encoderLayers, 2, current_batch_size, -1).sum(1),\n",
    "                    encoderCurrentState[1].view(encoder.encoderLayers, 2, current_batch_size, -1).sum(1)\n",
    "                )\n",
    "            else:\n",
    "                encoderCurrentState = encoderCurrentState.view(encoder.encoderLayers, 2, current_batch_size, -1).sum(1)\n",
    "\n",
    "        decoderCurrState = init_decoder_state(encoderCurrentState, encoder.encoderLayers, decoder.decoderLayers, cellType)\n",
    "\n",
    "        loss = 0\n",
    "        outputSeqLen = targetBatch.shape[1]\n",
    "        Output = []\n",
    "        randNumber = random.random()\n",
    "\n",
    "        for i in range(outputSeqLen):\n",
    "            if i == 0:\n",
    "                decoderInputensor = targetBatch[:, i].reshape(current_batch_size, 1)\n",
    "            else:\n",
    "                if randNumber < tf_ratio:\n",
    "                    decoderInputensor = targetBatch[:, i].reshape(current_batch_size, 1)\n",
    "                else:\n",
    "                    decoderInputensor = decoderInputensor.reshape(current_batch_size, 1)\n",
    "\n",
    "            decoderOutput, decoderCurrState = decoder(decoderInputensor, decoderCurrState)\n",
    "            _, topIndeces = decoderOutput.topk(1)\n",
    "            decoderOutput = decoderOutput[:, -1, :]\n",
    "            curr_target_chars = targetBatch[:, i].type(dtype=torch.long)\n",
    "            loss += lossFunction(decoderOutput, curr_target_chars)\n",
    "            decoderInputensor = topIndeces.squeeze().detach()\n",
    "            Output.append(decoderInputensor)\n",
    "\n",
    "        tensor_2d = torch.stack(Output)\n",
    "        Output = tensor_2d.t()\n",
    "        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n",
    "        validation_loss += (loss.item() / outputSeqLen)\n",
    "        total_samples += targetBatch.size(0)\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    return validation_accuracy, validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main_fun():\n",
    "    # Initialize a new W&B run for this sweep trial\n",
    "    wandb.init(project='CS23S025-Assignment-3-DL')\n",
    "\n",
    "    # Load the current configuration (set by W&B sweep agent)\n",
    "    params = wandb.config\n",
    "\n",
    "    # Train the model using the hyperparameters provided by the sweep\n",
    "    train(\n",
    "        params.embSize,\n",
    "        params.encoderLayers,\n",
    "        params.decoderLayers,\n",
    "        params.hiddenLayerNuerons,\n",
    "        params.cellType,\n",
    "        params.bidirection,\n",
    "        params.dropout,\n",
    "        params.epochs,\n",
    "        params.batchsize,\n",
    "        params.learningRate,\n",
    "        params.optimizer,\n",
    "        params.tf_ratio\n",
    "    )\n",
    "\n",
    "\n",
    "sweep_params = {\n",
    "    'method': 'bayes',  # Use Bayesian optimization (more sample-efficient than grid/random)\n",
    "    'name': 'Assignment_3_WITHOUT_Attention_2',  # Name of the sweep\n",
    "\n",
    "    # Define the target metric to optimize\n",
    "    'metric': {\n",
    "        'goal': 'maximize',\n",
    "        'name': 'validation_accuracy',  # Metric reported in wandb.log()\n",
    "    },\n",
    "\n",
    "    # Define the hyperparameter search space\n",
    "    'parameters': {\n",
    "        'embSize': {'values': [32, 64, 128, 256]},\n",
    "        'encoderLayers': {'values': [2, 3, 4, 5, 7]},\n",
    "        'decoderLayers': {'values': [2, 3, 4, 5]},\n",
    "        'hiddenLayerNuerons': {'values': [64, 256, 512]},\n",
    "        'cellType': {'values': ['GRU', 'RNN', 'LSTM']},\n",
    "        'bidirection': {'values': ['no', 'Yes']},  # Note: case-sensitive; use consistently in code\n",
    "        'dropout': {'values': [0, 0.2, 0.3, 0.5]},\n",
    "        'epochs': {'values': [10, 15, 20, 25]},\n",
    "        'batchsize': {'values': [32, 64, 128]},\n",
    "        'learningRate': {'values': [1e-2, 1e-3, 1e-4]},\n",
    "        'optimizer': {'values': ['Adam', 'Nadam']},\n",
    "        'tf_ratio': {'values': [0.2, 0.4, 0.5, 0.7]}  # Teacher forcing ratio\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweepId = wandb.sweep(sweep_params, project='CS23S025-Assignment-3-DL')\n",
    "wandb.agent(sweepId, function=main_fun, count=50, entity=\"cs23s025-indian-institute-of-technology-madras\", project=\"CS23S025-Assignment-3-DL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num_target = data['char_num_map_2']\n",
    "num_to_char_target = data['num_char_map_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Keys in the 'data' dictionary: {data.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import editdistance\n",
    "import csv\n",
    "\n",
    "# Character-to-index and index-to-character mappings for both source and target sequences\n",
    "char_to_num_target = data['char_num_map_2']\n",
    "num_to_char_target = data['num_char_map_2']\n",
    "char_to_num_source = data['char_num_map']\n",
    "num_to_char_source = data['num_char_map']\n",
    "\n",
    "# Hyperparameters for model architecture (must match the training config)\n",
    "embSize = 32\n",
    "encoderLayers = 3\n",
    "decoderLayers = 3\n",
    "hiddenLayerNuerons = 512\n",
    "cellType = \"GRU\"\n",
    "bidirection = 'no'\n",
    "dropout = 0.3\n",
    "epochs = 15\n",
    "batchsize = 64\n",
    "learningRate = 0.001\n",
    "optimizer = 'Nadam'\n",
    "tf_ratio = 1.0\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize encoder and decoder models with the same architecture as during training\n",
    "encoder = Encoder(\n",
    "    inputDim=data[\"source_len\"],\n",
    "    embSize=embSize,\n",
    "    encoderLayers=encoderLayers,\n",
    "    hiddenLayerNuerons=hiddenLayerNuerons,\n",
    "    cellType=cellType,\n",
    "    bidirection=bidirection\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    outputDim=data[\"target_len\"],\n",
    "    embSize=embSize,\n",
    "    hiddenLayerNuerons=hiddenLayerNuerons,\n",
    "    decoderLayers=decoderLayers,\n",
    "    cellType=cellType,\n",
    "    dropout_p=dropout\n",
    ").to(device)\n",
    "\n",
    "# Load the best saved model weights from training\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=device)\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Prepare the test dataset and data loader (batch_size=1 for evaluation)\n",
    "test_dataset = MyDataset(data_test[\"source_charToNum\"], data_test[\"val_charToNum\"])\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Maximum length of the target sequence for inference\n",
    "max_target_len = 23\n",
    "\n",
    "# Counters to compute test accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "print_limit = 10  # Limit the number of verbose printed examples\n",
    "\n",
    "# Utility function to clean predicted/target sequences by removing special tokens\n",
    "def clean(seq):\n",
    "    return ''.join(c for c in seq if c not in ('{', '}'))\n",
    "\n",
    "# Evaluation loop (inference without teacher forcing)\n",
    "with torch.no_grad():\n",
    "    for source_tensor, target_tensor in test_loader:\n",
    "        source_tensor = source_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "\n",
    "        # Initialize encoder hidden state\n",
    "        enc_hidden = encoder.initHidden(batch_size=1)\n",
    "\n",
    "        # Pass input through the encoder\n",
    "        encoder_outputs, enc_hidden = encoder(source_tensor, enc_hidden)\n",
    "\n",
    "        # Initialize decoder hidden state using encoder's final state\n",
    "        dec_hidden = init_decoder_state(enc_hidden, encoderLayers, decoderLayers, cellType)\n",
    "\n",
    "        # Start token for the decoder\n",
    "        decoder_input = torch.tensor([[char_to_num_target[\"{\"]]], device=device)\n",
    "\n",
    "        decoded_output = []  # Store predicted characters\n",
    "\n",
    "        # Generate one character at a time until max length or end token is reached\n",
    "        for _ in range(max_target_len):\n",
    "            decoder_output, dec_hidden = decoder(decoder_input, dec_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            next_index = topi.item()  # Get index of predicted token\n",
    "            next_char = num_to_char_target[next_index]\n",
    "\n",
    "            if next_char == \"}\":\n",
    "                break  # Stop decoding at end token\n",
    "\n",
    "            decoded_output.append(next_char)\n",
    "            decoder_input = torch.tensor([[next_index]], device=device)\n",
    "\n",
    "        # Convert input, target, and predicted sequences from index to character\n",
    "        input_seq = clean([num_to_char_source[i.item()] for i in source_tensor[0]])\n",
    "        target_seq = clean([num_to_char_target[i.item()] for i in target_tensor[0]])\n",
    "        predicted_seq = clean(decoded_output)\n",
    "\n",
    "        # Compare prediction to ground truth\n",
    "        if predicted_seq == target_seq:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "        # Print the first few predictions and some correct/incorrect cases\n",
    "        if total <= print_limit:\n",
    "            print(f\"Input:     {input_seq}\")\n",
    "            print(f\"Target:    {target_seq}\")\n",
    "            print(f\"Predicted: {predicted_seq}\\n\")\n",
    "\n",
    "        if total <= 3 or (total <= 20 and predicted_seq == target_seq):\n",
    "            print(f\"MATCH! Input: {input_seq} | Target: {target_seq} | Predicted: {predicted_seq}\")\n",
    "        elif total <= 20:\n",
    "            print(f\"DIFF!  Input: {input_seq} | Target: {target_seq} | Predicted: {predicted_seq}\")\n",
    "\n",
    "# Compute and print final test accuracy\n",
    "accuracy = correct / total * 100\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7419837,
     "sourceId": 11813384,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
